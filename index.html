<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>CS 330 Deep Multi-Task and Meta Learning</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author" content="samir" >

	<link href="css/bootstrap.min.css" rel="stylesheet">
	<link href="css/style.css" rel="stylesheet">
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">


	<!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
	<!--[if lt IE 9]>
		<script src="js/html5shiv.js"></script>
	<![endif]-->

   <script type="text/javascript" src="js/jquery.min.js"></script>
   <script type="text/javascript" src="js/bootstrap.min.js"></script>
   <script type="text/javascript" src="js/scripts.js"></script>
</head>

<body>
	<div class="container">
		<div class="row clearfix">
			<div class="col-md-12 column">
				<div class="row clearfix">
					<br/>
					<h1>CS 330:	Deep Multi-Task and Meta Learning</h2>
					<h3>Fall 2019, Class: Mon, Wed 1:30-2:50pm, Bishop Auditorium</h3>
					<br/>
          			<!-- <img alt="" class="pull" src="./images/frontfig-cs330-v2.jpg" style="width: 100%">
					<br/> -->
          			<!--img alt="" class="pull-right" src="./images/CS333-Pull-v1.jpg" style="width: 100%"-->
					<!--<div class="carousel slide" id="carousel-25687">
					<ol class="carousel-indicators">
						<li class="active" data-slide-to="0" data-target="#carousel-25687"> </li>
					</ol>
					<div class="carousel-inner">
						<div class="item active">
							<img alt="" align="left" src="./images/frontfig-cs333.png">
						</div>
          </div>
          </div>-->
          			<h3><font color="red"><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5">Lecture videos</a> are now available!</font></h3>
					<h3>Description:</h3>
                    <p>While deep learning has achieved remarkable success in supervised and reinforcement learning problems, such as image classification, speech recognition, and game playing, these models are, to a large degree, specialized for the single task they are trained for. This course will cover the setting where there are multiple tasks to be solved, and study how the structure arising from multiple tasks can be leveraged to learn more efficiently or effectively. This includes:</p>
                    <ul>
                        <li>goal-conditioned reinforcement learning techniques that leverage the structure of the provided goal space to learn many tasks significantly faster</li>
                        <li>meta-learning methods that aim to learn efficient learning algorithms that can learn new tasks quickly</li>
                        <li>curriculum and lifelong learning, where the problem requires learning a sequence of tasks, leveraging their shared structure to enable knowledge transfer</li>
                    </ul>
                    <p>This is a graduate-level course. By the end of the course, students will be able to understand and implement the state-of-the-art multi-task learning and meta-learning algorithms and be ready to conduct research on these topics.</p>
 
                    
					<h3>Format:</h3>
					<p>The course is a combination of lecture and reading sessions. The lectures will discuss the fundamentals of <a href="index.html#topics">topics</a> required for understanding and designing multi-task and meta-learning algorithms. During the reading sessions, students will present and discuss recent contributions and applications in this area. There will be three assignments. Throughout the semester, each student will also work on a related research project that they present at the end of the semester. <!--See detailed <a
                    href="#grading-policies">course policies.</a></p>-->
					<br>
					<h3>Prerequisites:</h3>
					<p>CS 229 or an equivalent introductory machine learning course is required. CS 221 or an equivalent introductory artificial intelligence course is recommended but not required.</p>
					<h3>Enrollment:</h3>
					<p>Please fill out this <a href="https://docs.google.com/forms/d/e/1FAIpQLSdNOgU5S_SIhk1A2W1tN82y17Bb1I7crIWoBjtKEC8tg3v2FQ/viewform">enrollment form</a> if you are interested in this course. See the form for more information on enrollment.</p>
				</div>

				<div class="hrline"> <hr /> </div>
				<div class="row clearfix">
					<h3> Staff </h3>
					<div class="row clearfix">
						<div class="col-md-2 column">
							<img class="img-thumbnail" src="images/chelsea.jpg" alt="Chelsea Finn" width="160" height="160">
							<h4>Prof. Chelsea Finn</h4>
							<h5>Instructor</h5>
							<h5>OH: Weds 3-4 pm</h4>
							<h5>Location: Gates 219</h4>
							<h5><a href="https://ai.stanford.edu/~cbfinn/">Webpage</a></h5>
						</div>
						<div class="col-md-2 column">
							<img class="img-thumbnail" src="images/suraj.jpg" alt="Suraj Nair" width="160" height="160">
							<h4>Suraj Nair</h4>
							<h5>Teaching Assistant</h5>
							<h5>OH: Thurs 7-8 pm</h4>
							<h5>Location: Gates 167</h4>
							<h5><a href="https://cs.stanford.edu/~surajn/">Webpage</a></h5>
						</div>
						<div class="col-md-2 column">
							<img class="img-thumbnail" src="images/kevin.png" alt="Tianhe Yu" width="160" height="160">
							<h4>Tianhe (Kevin) Yu</h4>
							<h5>Teaching Assistant</h5>
							<h5>OH: Mon 10:30-11:30 am</h4>
							<h5>Location: Gates B21</h4>
							<h5><a href="https://cs.stanford.edu/~tianheyu/">Webpage</a></h5>
						</div>
						<div class="col-md-2 column">
							<img class="img-thumbnail" src="images/abhishek.jpg" alt="Abhishek Sinha" width="160" height="160">
							<h4>Abhishek Sinha</h4>
							<h5>Teaching Assistant</h5>
							<h5>OH: Tue 4:30-5:30 pm</h4>
							<h5>Location: Gates 259</h4>
                            <h5><a href="https://a7b23.github.io/">Webpage</a></h5>
						</div>
						<div class="col-md-2 column">
							<img class="img-thumbnail" src="images/tim.jpg" alt="Tim Liu" width="160" height="160">
							<h4>Tim Liu</h4>
							<h5>Teaching Assistant</h5>
							<h5>OH: Fri 4:30-5:30 pm</h4>
							<h5>Location: Gates 358</h4>
                            <h5><a href="https://timsliu.org/">Webpage</a></h5>
						</div>
	
					</div>
				</div>

				<div class="hrline"> <hr /> </div> <br>
				<h3 id="topics">Tentative Timeline</h3>
				<table class="table">
					<thead>
						<tr>
							<th style="width: 12%">Date</th>
							<th style="width: 23%">Lecture</th>
							<th style="width: 50%">Handouts / Deadlines</th>
							<th style="width: 15%">Notes</th>
						</tr>
					</thead>
					<tbody>
						<tr class="active">
							<td><b>Week 1</b><br/> 
								Mon, Sep 23
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_lecture1.pdf">Course introduction, problem definitions, applications</a></td>
							<td>
							<td>
								<a href="https://www.youtube.com/watch?v=0rZtSwNOTQo&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=1">Lecture Video</a>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 1</b><br/> 
								Wed, Sep 25
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_lec2.pdf">Supervised multi-task learning, black-box meta-learning</a></td>
							<td>
								<b> Homework 1 out</b>
							</td>
							<td>
								 <a href="https://www.youtube.com/watch?v=6stKGH6zI8g&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=2">Lecture Video</a><br/> 
								 HW1 [<a href="material/homework_1_updated.pdf">pdf</a>][<a href="material/hw1_updated.zip">zip</a>]
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 1</b><br/> 
								Thu, Sep 26
							</td>
							<td><i><span class="label label-lecture text-base">TA Session</span></i> <a href="material/Tensorflow&#32;(1.x)&#32;Review&#32;Session.pdf">TensorFlow tutorial</a></td>
							<td>
							</td>
							<td>
								<a href="material/TF&#32;Recitation.ipynb.html">TF notebook</a>
							</td>
						</tr>
						<tr>
							<td><b>Week 2</b><br/> 
								Mon, Sep 30
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_lecture3.pdf">Optimization-based meta-learning</a></td>
							<td>
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=v7otSgpTc0Q&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=3">Lecture Video</a>
							</td>
						</tr>
						<tr>
							<td><b>Week 2</b><br/> 
								Wed, Oct 02
							</td>
							<td><i><span class="label label-reading text-base">Reading</span></i> Applications in imitation learning, vision, language, generative models</td>
							<td>
								<ul> 
								<!-- <li> <a href="https://www.facebook.com/icml.imls/videos/tutorial-session-optimization-perspectives-on-learning-to-control/428757614305426/"> ICML 2018 Tutorial on Optimal Control </a>, Ben Recht </li> -->
									<li> <a href="https://arxiv.org/abs/1808.08437"> P1: Meta-Learning for Low-Resource Neural Machine Translation.</a> Gu et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1710.10304"> P2: Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions.</a> Reed et al. (2017)</li>
									<li> <a href="https://arxiv.org/abs/1703.07326"> P3: One-Shot Imitation Learning.</a> Duan et al. (2017)</li>
									<li> <a href="https://arxiv.org/pdf/1502.02072.pdf"> P4: Massively Multitask Networks for Drug Discovery.</a> Ramsundar et al. (2015)</li>
								</ul>
							</td>
							<td>
								Presentation slides [<a href="presentations/presentation-10.2-1.pdf">P1</a>][<a href="presentations/presentation-10.2-2.pdf">P2</a>][<a href="presentations/presentation-10.2-3.pdf">P3</a>][<a href="presentations/presentation-10.2-4.pdf">P4</a>]
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 3</b><br/> 
								Mon, Oct 7
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_lecture4.pdf">Few-shot learning via metric learning</a></td>
							<td>
								<!-- <ul>
									<li> <a href="https://people.csail.mit.edu/lpk/papers/hpnICRA11Final.pdf"> P1: Hierarchical Task and Motion Planning in the Now.</a> Kaelbling et al. (2011)</li>
									<li> <a href="http://www.roboticsproceedings.org/rss14/p44.pdf"> P2: Differentiable Physics and Stable Modes for Tool-Use and Manipulation Planning.</a> Toussaint et al. (2018)</li>
									<li> P1 Supplementary: Integrated task and motion planning in belief space. Kaelbling et al. (2013) </li>
								</ul> -->
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=bc-6tzTyYcM&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=4">Lecture Video</a><br/> 
								<a href="material/CS330_Final_Project_Guidelines.pdf">Final Project Guidelines</a>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 3</b><br/> 
								Wed, Oct 09
							</td>
							<td><i><span class="label label-reading text-base">Reading</span></i> Hybrid meta-learning approaches</td>
							<td>
								<span class="label label-due text-base">Due</span></i><b> Homework 1</b><br>
								<b> Homework 2 out</b>
								<ul> 
									<li> <a href="https://arxiv.org/abs/1807.05960"> P1: Meta-Learning with Latent Embedding Optimization.</a> Rusu et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1810.03642"> P2: Fast Context Adaptation via Meta-Learning.</a> Zintgraf et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1903.03096"> P3: Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples.</a> Triantafillou et al. (2019)</li>
									<li> <a href="https://arxiv.org/abs/1711.04043"> P4: Few-Shot Learning with Graph Neural Networks.</a> Garcia et al. (2017)</li>
								</ul>
							</td>
							<td>
								HW2 [<a href="material/CS330_homework2.pdf">pdf</a>][<a href="material/HW2.zip">zip</a>]<br>
								Presentation slides [<a href="presentations/presentation-10.9-1.pptx">P1</a>][<a href="presentations/presentation-10.9-2.pptx">P2</a>][<a href="presentations/presentation-10.9-3.pptx">P3</a>][<a href="presentations/presentation-10.9-4.pptx">P4</a>]
							</td>
						</tr>
						<tr>
							<td><b>Week 4</b><br/> 
								Mon, Oct 14
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_bayesian_metalearning.pdf">Bayesian meta-learning</a></td>
							<td>
								<!-- <ul>
									<li>Socially Compliant Mobile Robot Navigation via IRL.</a> Kretzschmar, et al. (2016).</li>
									<li>Predicting Human Reaching Motion in Collaborative Tasks using Inverse Optimal Control and Iterative re-planning.</a> Mainprice, et al. (2015).</li>
									<li>Infant Imitation After a 1-Week Delay. Meltzoff, et al. (1988).</li>
									<li>Planning Based Prediction for Pedestrians. Ziebart, et al. (2009).</li>
								</ul> -->
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=QY8JXpnllb0&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=5">Lecture Video</a>
							</td>
						</tr>
						<tr>
							<td><b>Week 4</b><br/> 
								Wed, Oct 16
							</td>
							<td><i><span class="label label-reading text-base">Reading</span></i> Meta-learning for active learning, weakly-supervised learning, unsupervised learning</td>
							<td>
								<ul> 
									<li> <a href="https://arxiv.org/abs/1804.00222"> P1: Meta-Learning Update Rules for Unsupervised Representation Learning.</a> Metz et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1708.00088"> P2: Learning Algorithms for Active Learning.</a> Bachman et al. (2017)</li>
									<li> <a href="https://arxiv.org/abs/1802.01557"> P3: One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning.</a> Yu et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1803.00676"> P4: Meta-Learning for Semi-Supervised Few-Shot Classification.</a> Ren et al. (2018)</li>
								</ul>
							</td>
							<td>
								Presentation slides [<a href="presentations/presentation-10.16-1.pdf">P1</a>][<a href="presentations/presentation-10.16-2.pdf">P2</a>][<a href="presentations/presentation-10.16-3.pdf">P3</a>][<a href="presentations/presentation-10.16-4.pdf">P4</a>]
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 5</b><br/> 
								Mon, Oct 21
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_mtrl.pdf">Renforcement learning primer, multi-task RL, goal-conditioned RL</a></td>
							<td>
								<!-- <ul>
									<li>Socially Compliant Mobile Robot Navigation via IRL.</a> Kretzschmar, et al. (2016).</li>
									<li>Predicting Human Reaching Motion in Collaborative Tasks using Inverse Optimal Control and Iterative re-planning.</a> Mainprice, et al. (2015).</li>
									<li>Infant Imitation After a 1-Week Delay. Meltzoff, et al. (1988).</li>
									<li>Planning Based Prediction for Pedestrians. Ziebart, et al. (2009).</li>
								</ul> -->
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=UPT4Rndftc8&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=6">Lecture Video</a>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 5</b><br/> 
								Wed, Oct 23
							</td>
							<td><i><span class="label label-reading text-base">Reading</span></i> Auxiliary objectives, state representation learning</td>
							<td>
								<span class="label label-due text-base">Due</span></i><b> Homework 2</b><br>
								<b> Homework 3 out</b><br>
								<ul> 
									<li> <a href="https://arxiv.org/abs/1810.04805"> P1: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</a> Devlin et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1710.02298"> P2: Rainbow: Combining Improvements in Deep Reinforcement Learning.</a> Hessel et al. (2017)</li>
									<li> <a href="https://arxiv.org/abs/1907.00953"> P3: Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model.</a> Lee et al. (2019)</li>
									<li> <a href="http://roboticsproceedings.org/rss10/p19.pdf"> P4: State Representation Learning in Robotics: Using Prior Knowledge about Physical Interaction.</a> Jonschkowski et al. (2010)</li>
								</ul>
							</td>
							<td>
								HW3 [<a href="material/CS330_HW3.pdf">pdf</a>][<a href="material/hw3.zip">zip</a>]<br>
								Presentation slides [<a href="presentations/presentation-10.23-1.pdf">P1</a>][<a href="presentations/presentation-10.23-2.pdf">P2</a>][<a href="presentations/presentation-10.23-3.pdf">P3</a>][<a href="presentations/presentation-10.23-4.pdf">P4</a>]
							</td>
						</tr>
						<tr>
							<td><b>Week 6</b><br/> 
								Mon, Oct 28
							</td>
							<td><i><span class="label label-reading text-base">Reading</span></i> Hierarchical RL, curriculum generation</td>
							<td>
								<ul> 
									<li> <a href="https://www.sciencedirect.com/science/article/pii/S0004370299000521"> P1: Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning.</a> Sutton et al. (1999)</li>
									<li> <a href="https://arxiv.org/abs/1610.05182"> P2: Learning and Transfer of Modulated Locomotor Controllers.</a> Heess et al. (2016)</li>
									<li> <a href="https://arxiv.org/abs/1805.08296"> P3: Data-Efficient Hierarchical Reinforcement Learning.</a> Nachum et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1906.07343"> P4: Language as an Abstraction for Hierarchical Deep Reinforcement Learning.</a> Jiang et al. (2019)</li>
								</ul>
							</td>
							<td>
								Presentation slides [<a href="presentations/presentation-10.28-1.pdf">P1</a>][<a href="presentations/presentation-10.28-2.pdf">P2</a>][<a href="presentations/presentation-10.28-3.pdf">P3</a>][<a href="presentations/presentation-10.28-4.pdf">P4</a>]
							</td>
						</tr>
						<tr>
							<td><b>Week 6</b><br/> 
								Wed, Oct 30
							</td>
							<td><i><span class="label label-guest text-base">Guest Lecture</span></i> <a href="slides/Exploration&#32;in&#32;Meta-RL.pdf">Meta-RL, learning to explore</a></td>
							<td>
								<span class="label label-due text-base">Due</span></i><b> Project proposal</b><br>
								<a href="https://people.eecs.berkeley.edu/~rakelly/">Kate Rakelly</a>, UC Berkeley
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=k6rL4wzykGA&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=7">Lecture Video</a>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 7</b><br/> 
								Mon, Nov 04
							</td>
							<td><i><span class="label label-reading text-base">Reading</span></i> Meta-RL and emergent phenomenon</td>
							<td>
								<ul> 
									<li> <a href="https://www.biorxiv.org/content/10.1101/295964v2"> P1: Prefrontal Cortex as a Meta-Reinforcement Learning System.</a> Wang et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1901.08162"> P2: Causal Reasoning from Meta-reinforcement Learning.</a> Dasgupta et al. (2019)</li>
									<li> <a href="https://arxiv.org/abs/1710.03748"> P3: Emergent Complexity via Multi-Agent Competition.</a> Bansal et al. (2017)</li>
									<li> <a href="https://arxiv.org/abs/1711.00482"> P4: Learning with Latent Language.</a> Andreas et al. (2017)</li>
								</ul>
							</td>
							<td>
								Presentation slides [<a href="presentations/presentation-11.4-1.pdf">P1</a>][<a href="presentations/presentation-11.4-2.pdf">P2</a>][<a href="presentations/presentation-11.4-3.pdf">P3</a>][<a href="presentations/presentation-11.4-4.pdf">P4</a>]
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 7</b><br/> 
								Wed, Nov 06
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_mbrl.pdf">Model-based RL for multi-task learning, meta model-based RL</a></td>
							<td>
								<span class="label label-due text-base">Due</span></i><b> Homework 3</b><br>
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=NBjcWPcCccA&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=8">Lecture Video</a>
							</td>
						</tr>
						<tr>
							<td><b>Week 8</b><br/> 
								Mon, Nov 11
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i> <a href="slides/cs330_lifelonglearning.pdf">Lifelong learning: problem statement, forward & backward transfer</a></td>
							<td>
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=c6VpDHoUIjQ&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=9">Lecture Video</a>
							</td>
						</tr>
						<tr>
							<td><b>Week 8</b><br/> 
								Wed, Nov 13
							</td>
							<td><i><span class="label label-reading text-base">Reading</span></i> Miscellaneous multi-task/meta-RL topics</td>
							<td>
								<span class="label label-due text-base">Due</span></i><b> Project milestone</b><br>
								<ul> 
									<li> <a href="https://arxiv.org/abs/1904.11455"> P1: Ray Interference: a Source of Plateaus in Deep Reinforcement Learning.</a> Schaul et al. (2019)</li>
									<li> <a href="https://arxiv.org/abs/1802.05098"> P2: DiCE: The Infinitely Differentiable Monte-Carlo Estimator.</a> Foerster et al. (2018)</li>
									<li> <a href="https://arxiv.org/abs/1611.04201"> P3: CAD2RL: Real Single-Image Flight without a Single Real Image.</a> Sadeghi et al. (2016)</li>
									<li> <a href="https://arxiv.org/abs/1810.06544"> P4: Deep Imitative Models for Flexible Inference, Planning, and Control.</a> Rhinehart et al. (2018)</li>
								</ul>
							</td>
							<td>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 9</b><br/>
								Mon, Nov 18
							</td>
                            <td><i><span class="label label-guest text-base">Guest Lecture</span></i> TBD</td>
							<td>
								<a href="http://jeffclune.com/">Jeff Clune</a>, University of Wyoming / Uber
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=cZUdaqTC1TA&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=10">Lecture Video</a>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 9</b><br/> 
								Wed, Nov 20
							</td>
							<td><i><span class="label label-guest text-base">Guest Lecture</span></i> Information theoretic exploration</td>
							<td>
								<a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>, UC Berkeley
							</td>
							<td>
								<a href="https://www.youtube.com/watch?v=uPhvBxjiFE4&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=11">Lecture Video</a>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 10</b><br/>
								Mon, Nov 25
							</td>
							<td>Thanksgiving Break</td>
							<td></td>
							<td></td>
						</tr>
						<tr class="active">
							<td><b>Week 10</b><br/>
								Wed, Nov 27</td>
							<td>Thanksgiving Break</td>
							<td></td>
							<td></td>
						</tr>
						<tr class="active">
							<td><b>Week 11</b><br/> 
								Mon, Dec 02
							</td>
							<td><i><span class="label label-lecture text-base">Lecture</span></i><a href="slides/cs330_openchallenges">Frontiers: Memorization, unsupervised meta-learning, open problems</a></td>
							<td></td>
							<td>
								<a href="https://www.youtube.com/watch?v=o8CLDEAGXGo&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=12">Lecture Video</a>
							</td>
						</tr>
						<tr class="active">
							<td><b>Week 11</b><br/> 
								Tue, Dec 03
							</td>
							<td><i><span class="label label-presentation text-base">Presentation</span></i></td>
							<td><b> Poster Presentation 1:30 - 3:30 pm @ Packard Atrium</b></td>
							<td></td>
						</tr>
						<tr>
							<td><b>Week 13</b><br/> 
								Mon, Dec 16
							</td>
							<td>No Class</td>
							<td><span class="label label-due text-base">Due</span><b> Final Project Report (Deadline at 11:59 pm PT)</b></td>
							<td></td>
						</tr>
					</tbody>
				</table>

				<br>
				<div class="hrline"> <hr /> </div>
				<br>
				</div>

				<div id="financial-aid">
					<h3> Note on Financial Aid </h3>
					<br>
					 <p>All students should retain receipts for books and other course-related expenses, as these may be qualified educational expenses for tax purposes. If you are an undergraduate receiving financial aid, you may be eligible for additional financial aid for required books and course materials if these expenses exceed the aid amount in your award letter. For more information, review your award letter or visit the <a href="https://financialaid.stanford.edu/undergrad/budget/index.html">Student Budget website</a>. </p>
				</div>

				<div id="all-projects">
					<h3><a href="index.html#all-projects">All Projects</a></h3>
					<ul>
					  <li><strong>Weighted Gradient MAML</strong>.
					  	<br>
					 <em>Andrew Zhou Wang, Daniel Kang, Rohan Badlani </em></li>
					  <li><strong>Estimating the Degree of Shared Representation in Multi-Task Learning</strong>.
					  	<br>
					 <em>Benjamin Petit, Will Deaderick</em></li>
					  <li><strong>Learning to Adapt to Various Surfaces in Autonomous Driving</strong>.
					  	<br>
					 <em>Nathan Spielberg</em></li>
					  <li><strong>Activation Patterns of Policy Networks trained with Multi-Task and Meta-RL</strong>.
					  	<br>
					 <em>Ruilin Li</em></li>
					  <li><strong>Few-Shot Video Classification with Linear Base Learners</strong>.
					  	<br>
					 <em>Kevin Shin Tan</em></li>
					  <li><strong>Meta-Learning Symbolic, String-Based Concepts</strong>.
					  	<br>
					 <em>Allen Nie, Andrew Nam, Katherine L. Hermann</em></li>
					  <li><strong>Meta-Learning Hierarchical Policies</strong>.
					  	<br>
					 <em>Rafael Mitkov Rafailov, Riley DeHaan</em></li>
					  <li><strong>Hyperspherical Prototype Networks for Semi-Supervised Learning</strong>.
					  	<br>
					 <em>Daniel Tan, Ryan Arthur Tolsma</em></li>
					  <li><strong>Using curiosity as an Intrinsic Reward for Policy Gradient Methods</strong>.
					  	<br>
					 <em>Adam Harrison Williams</em></li>
					  <li><strong>Emergence of Modular Functional Groups through Attention</strong>.
					  	<br>
					 <em>Dian Ang Yap, Josh Payne, Vineet Sai Kosaraju</em></li>
					  <li><strong>Multi-Task Learning for Weakly Supervised Name Entity Recognition</strong>.
					  	<br>
					 <em>Saelig Ashank Khattar, Jason Fries</em></li>
					  <li><strong>Quantifying and Evaluating Positive Transfer in Multi-Task and Meta-Learning in NLP Tasks</strong>.
					  	<br>
					 <em>Daniel Alexander Salz, Hanoz Bhathena, Siamak shakeri</em></li>
					  <li><strong>Meta-Learning for Compensating for Sensor Drift and Noise in Aptamer E-chem Kinetic Data</strong>.
					  	<br>
					 <em>Louis Blankemeier</em></li>
					  <li><strong>Meta-Learning for Low Resource Question Answering</strong>.
					  	<br>
					 <em>Anirudh Rajiv Joshi, Ayush Agarwal, Raul Puri</em></li>
					  <li><strong>Few-Shot Object Detection with Prototypical RetinaNet</strong>.
					  	<br>
					 <em>John Weston Hughes, Kamil Ali</em></li>
					  <li><strong>Distributionally Robust Meta-Learning</strong>.
					  	<br>
					 <em>Yining Chen, Yue Hui</em></li>
					  <li><strong>Single Molecule Localization Microscopy with Meta-Learning</strong>.
					  	<br>
					 <em>Hsiang-Yu Yang</em></li>
					  <li><strong>Learning to be Safe</strong>.
					  	<br>
					 <em>Krishnan Srinivasan, Samuel Clarke</em></li>
					  <li><strong>Multi-Task Learning for Mathematical Problem Solving</strong>.
					  	<br>
					 <em>Justin Dieter</em></li>
					  <li><strong>Automatical Web Navigation via Unsupervised and Few-Shot Learning</strong>.
					  	<br>
					 <em>Nikhil Cheerla, Rohan Suri</em></li>
					  <li><strong>Meta-GAN for Few-Shot Image Classification with Data Augmentation</strong>.
					  	<br>
					 <em>Jc Charles Peruzzi, Mason Riley Swofford, Nikita-Girey Nechvet Demir</em></li>
					  <li><strong>Meta-Learning of Visual Tasks with AutoBAHNNs: Autoencoder-like Biological-Artifical Hybrid Neural Networks</strong>.
					  	<br>
					 <em>George Sivulka, Josh Brendan Melander</em></li>
					  <li><strong>Meta-Learning with PCGrad and Hessian Regularization</strong>.
					  	<br>
					 <em>Alex Mckeehan</em></li>
					  <li><strong>Learning Higher-Order Representations of Networks via Pretraining on the Subgraph Matching Problem</strong>.
					  	<br>
					 <em>Sabri Eyuboglu</em></li>
					  <li><strong>Explainable Bayesian Multi-modal Meta-Learning: Quantifying Uncertainty of Subspace Structures</strong>.
					  	<br>
					 <em>Lijing Wang</em></li>
					  <li><strong>Representation Learning for Classification</strong>.
					  	<br>
					 <em>Geoffrey Lim Angus</em></li>
					  <li><strong>Meta-Kernels for MAML</strong>.
					  	<br>
					 <em>Mansheej Paul, Saarthak Sarup</em></li>
					  <li><strong>Apply Meta-Learning to Predict Business Success</strong>.
					  	<br>
					 <em>Chenchen Pan</em></li>
					  <li><strong>Meta-Learning Semi-parametric Image Classification</strong>.
					  	<br>
					 <em>Henrik Marklund</em></li>
					  <li><strong>Hierarchical and Meta-Learning Methods for MineRL</strong>.
					  	<br>
					 <em>Jeffrey Gu</em></li>
					  <li><strong>FLEO: Flow-Bsed Latent Embedding Optimization for Few-Shot Meta-Learning</strong>.
					  	<br>
					 <em>Karen Yang, Todd Francis Macdonald</em></li>
					  <li><strong>k-AML: k-Attractor Meta Learning</strong>.
					  	<br>
					 <em>Advay Pal, Behzad Haghgoo, Megumi Sano</em></li>
					  <li><strong>Meta-Hierarchical RL</strong>.
					  	<br>
					 <em>Tian Tan, Ye Ye, Zhihan Xiong</em></li>
					  <li><strong>Meta-Batch RL</strong>.
					  	<br>
					 <em>Albert Jia-Xiang Tung, Jonathan Austin Booher</em></li>
					  <li><strong>Meta-Learning for Global Satellite-Based Land Cover Classification</strong>.
					  	<br>
					 <em>Sherrie Wang</em></li>
					  <li><strong>Meta-Ensembles for Epistemic Uncertainty in Few-Task Meta Learning</strong>.
					  	<br>
					 <em>Apoorva Sharma </em></li>
					  <li><strong>Meta-Learning for Autonomous Vehicle Safety Validation</strong>.
					  	<br>
					 <em>Anthony Louis Corso</em></li>
					  <li><strong>Large Scale Authorship Attribution with Meta-Learning with Latent Embedding Space Optimization</strong>.
					  	<br>
					 <em>Juanita Ordonez</em></li>
					  <li><strong>Bridging Weakly/Semi-Supervised Learning via Meta Learning</strong>.
					  	<br>
					 <em>Hao Sheng, Huanzhong Xu, Xiao Chen </em></li>
					  <li><strong>Review/Comparison on Gradient-Based Meta Learning Algorithms</strong>.
					  	<br>
					 <em>Jongho Kim</em></li>
					  <li><strong>Multi-Tak Manipulation of Deformable Objects</strong>.
					  	<br>
					 <em>Neel Sesh Ramachandran, Varun Nambiar</em></li>
					  <li><strong>You Just Have to Believe: Meta-Learning for Bayesian Reinforcement Learning</strong>.
					  	<br>
					 <em>Preston Davis Culbertson</em></li>
					  <li><strong>Meta-Learning with PCGrad</strong>.
					  	<br>
					 <em>Jo C H Chuang, Tom Knowles</em></li>
					</ul>
				</div>
                
			</div>
		</div>
		<br>


		<!-- The footer -->
		<div class="hrline"><hr></div><br>
		<div class="row clearfix">
			<div class="col-md-3 column">
			</div>
			<div class="col-md-6 column">
				<div class = "text-center">
					<p>
					&nbsp;&nbsp;&nbsp; &#169; Chelsea Finn 2019
					</p>
				</div>
			</div>
			<div class="col-md-3 column">
			</div>
		</div>
		<br>
		<br>
		<br>
		<!-- End of document -->
	</div>
</body>
</html>
